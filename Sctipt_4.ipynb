{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "# linear algebra\n",
    "import numpy as np \n",
    "\n",
    "# data processing\n",
    "import pandas as pd \n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import svm\n",
    "\n",
    "#Import Gaussian Naive Bayes model\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#Import Random Forest Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# csv file manipulation\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read training data \n",
    "df = pd.read_csv('./data/train.csv')\n",
    "\n",
    "# read testing data\n",
    "test_df = pd.read_csv('./data/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "check for columns with missing values\n",
    "\n",
    "After loading the training and the testing dataset as pandas dataframes, the test data is pre-processed. The given dataset is first processed to remove records with missing values for duration and the fare. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().any())\n",
    "df = df.dropna(subset=['duration', 'fare'])\n",
    "print(df['duration'].isnull().values.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then the feature extraction has taken place to better understand the features of the dataset. \n",
    "\n",
    "1.\ttrip_duration = duration - (meter_waiting_till_pickup + meter_waiting)\n",
    "2.\ttrip_fare = fare - ( additional_fare + meter_waiting_fare)\n",
    "\n",
    "\n",
    "The feature extraction was done to both training and testing data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['trip_duration'] = df['duration']- (df['meter_waiting_till_pickup'] + df['meter_waiting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['trip_duration'] = test_df['duration']- (test_df['meter_waiting_till_pickup'] + test_df['meter_waiting'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['trip_fare'] = df['fare'] -  (df['additional_fare'] + df['meter_waiting_fare'])\n",
    "test_df['trip_fare'] = test_df['fare'] -  (test_df['additional_fare'] + test_df['meter_waiting_fare'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the training dataset is splitted into labels ‘Y’ and features ‘X’. In order to write the results against the trip_id, a list of trip identification numbers are created from the testing set. Then after that, trip_id attribute is removed from both training and testing datasets. \n",
    "\n",
    "As the models performed best when the pickup_time and drop_time were removed, those features were removed from the data in the next step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#split into data and label\n",
    "Y = df['label'] # label set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "tripIds = test_df['tripid'] # separate tripid to use when the results are written back to the submission\n",
    "\n",
    "#remove attributes\n",
    "test_df = test_df.drop(columns=['tripid', 'pickup_time', 'drop_time'])\n",
    "\n",
    "X = df.drop(columns=['tripid', 'label', 'pickup_time', 'drop_time'])\n",
    "\n",
    "X_test = test_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After all those steps, the data is standardized with sklearn.preprocessing, StandardScaler. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Scaling\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RandomForest classifier is used as the classification algorithm and the function RFClassifier is created to accept three parameters, \n",
    "    Training feature set\n",
    "    Training labels\n",
    "    Testing feature set\n",
    "\n",
    "And returns the predicted result set as the output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def RFClassifier(X_train, y_train, X_test):\n",
    "   \n",
    "    #Create the Classifier\n",
    "    clf=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "    #Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "    clf.fit(X_train,y_train)\n",
    "\n",
    "    y_pred=clf.predict(X_test)\n",
    "    \n",
    "    return y_pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = RFClassifier(X_train,Y, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function write_output is created to write the predicted out into the form required by the kaggle submission and this uses the extracted trip_id attributes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_output(Y_prediction):\n",
    "    with open('sampleSubmission.csv', 'w', newline='') as csvfile:\n",
    "        fieldnames = ['tripid', 'prediction']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "        writer.writeheader()\n",
    "        line = 0\n",
    "    \n",
    "        for w in Y_prediction:\n",
    "            output = 1\n",
    "            if (w == 'incorrect'):\n",
    "                output = 0\n",
    "            writer.writerow({'tripid': tripIds[line], 'prediction': output})\n",
    "            line = line+1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After calling the function RFClassifier, the returned result set is passed to the function write_output to write to sampleSubmission.csv file of the given location. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_output(Y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
